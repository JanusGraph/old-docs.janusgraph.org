<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>Chapter&nbsp;33.&nbsp;Bulk Loading</title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="JanusGraph Documentation"><link rel="up" href="advanced.html" title="Part&nbsp;V.&nbsp;Advanced Topics"><link rel="prev" href="index-admin.html" title="Chapter&nbsp;32.&nbsp;Index Management"><link rel="next" href="graph-partitioning.html" title="Chapter&nbsp;34.&nbsp;Graph Partitioning"><script xmlns:d="http://docbook.org/ns/docbook" type="text/javascript" src="js/jquery/jquery-1.11.0.js"></script><script xmlns:d="http://docbook.org/ns/docbook" type="text/javascript" src="js/jquery/jquery-migrate-1.2.1.min.js"></script><link xmlns:d="http://docbook.org/ns/docbook" rel="stylesheet" id="inline-blob-janusgraph-docs-specific" href="css/docs.css" type="text/css" media="all"><link xmlns:d="http://docbook.org/ns/docbook" rel="apple-touch-icon" type="image/png" href="images/janusgraph-logomark.png"><script xmlns:d="http://docbook.org/ns/docbook" type="text/javascript">
      WebFontConfig = {
        google: {
          families: [
            "Lato:400,400italic,700,700italic:latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese",
            "Open+Sans:400,400italic,700,700italic:latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese",
            "Antic+Slab:400,400italic,700,700italic:latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese"
          ]
        }
      };
      (function() {
      var wf = document.createElement('script');
      wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
        '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
	wf.type = 'text/javascript';
	wf.async = 'true';
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(wf, s);
	})();
    </script></head><body xmlns:d="http://docbook.org/ns/docbook" bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div id="wrapper"><div class="header-wrapper"><header id="header"><ul class="header-list"><li class="header-item"><a href="http://janusgraph.org"><img src="images/janusgraph-logo.png" alt="JanusGraph" class="normal_logo"></a></li><li class="header-item-right"><a href="https://github.com/JanusGraph/janusgraph/releases">Download JanusGraph</a></li><li class="header-item-right dropdown"><a href="https://docs.janusgraph.org/latest/doc-versions.html">Other Doc Versions</a><div class="dropdown-content"><a href="https://docs.janusgraph.org/latest/index.html">Latest</a><a href="https://docs.janusgraph.org/0.3.0/index.html">Version 0.3.0</a><a href="https://docs.janusgraph.org/0.2.2/index.html">Version 0.2.2</a><a href="https://docs.janusgraph.org/0.2.1/index.html">Version 0.2.1</a><a href="https://docs.janusgraph.org/0.2.0/index.html">Version 0.2.0</a><a href="https://docs.janusgraph.org/0.1.1/index.html">Version 0.1.1</a><a href="https://docs.janusgraph.org/0.1.0/index.html">Version 0.1.0</a></div></li><li class="header-item-right"><a href="index.html">Documentation (0.2.2)</a></li></ul></header></div><div id="main" class="clearfix width-100"><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">JanusGraph Documentation</a></span> &gt; <span class="breadcrumb-link"><a href="advanced.html">Advanced Topics</a></span> &gt; <span class="breadcrumb-node">Bulk Loading</span></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="bulk-loading"></a>Chapter&nbsp;33.&nbsp;Bulk Loading</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl class="toc"><dt><span class="section"><a href="bulk-loading.html#_configuration_options_2">33.1. Configuration Options</a></span></dt><dd><dl><dt><span class="section"><a href="bulk-loading.html#_batch_loading">33.1.1. Batch Loading</a></span></dt><dt><span class="section"><a href="bulk-loading.html#_optimizing_id_allocation">33.1.2. Optimizing ID Allocation</a></span></dt><dt><span class="section"><a href="bulk-loading.html#_optimizing_writes_and_reads">33.1.3. Optimizing Writes and Reads</a></span></dt></dl></dd><dt><span class="section"><a href="bulk-loading.html#_strategies">33.2. Strategies</a></span></dt><dd><dl><dt><span class="section"><a href="bulk-loading.html#_parallelizing_the_load">33.2.1. Parallelizing the Load</a></span></dt></dl></dd><dt><span class="section"><a href="bulk-loading.html#_q_a">33.3. Q&amp;A</a></span></dt></dl></div><p>There are a number of configuration options and tools that make ingesting large amounts of graph data into JanusGraph more efficient. Such ingestion is referred to as <span class="emphasis"><em>bulk loading</em></span> in contrast to the default <span class="emphasis"><em>transactional loading</em></span> where small amounts of data are added through individual transactions.</p><p>There are a number of use cases for bulk loading data into JanusGraph, including:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Introducing JanusGraph into an existing environment with existing data and migrating or duplicating this data into a new JanusGraph cluster.</li><li class="listitem">Using JanusGraph as an end point of an <a class="link" href="http://en.wikipedia.org/wiki/Extract,_transform,_load" target="_top">ETL</a> process.</li><li class="listitem">Adding an existing or external graph datasets (e.g. publicly available <a class="link" href="http://linkeddata.org/" target="_top">RDF datasets</a>) to a running JanusGraph cluster.</li><li class="listitem">Updating a JanusGraph graph with results from a graph analytics job.</li></ul></div><p>This page describes configuration options and tools that make bulk loading more efficient in JanusGraph. Please observe the limitations and assumptions for each option carefully before proceeding to avoid data loss or data corruption.</p><p>This documentation focuses on JanusGraph specific optimization. In addition, consider improving the chosen storage backend and (optional) index backend for high write performance. Please refer to the documentation of the respective backend for more information.</p><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configuration_options_2"></a>33.1.&nbsp;Configuration Options</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_batch_loading"></a>33.1.1.&nbsp;Batch Loading</h3></div></div></div><p>Enabling the <code class="literal">storage.batch-loading</code> configuration option will have the biggest positive impact on bulk loading times for most applications. Enabling batch loading disables JanusGraph internal consistency checks in a number of places. Most importantly, it disables locking. In other words, JanusGraph assumes that the data to be loaded into JanusGraph is consistent with the graph and hence disables its own checks in the interest of performance.</p><p>In many bulk loading scenarios it is significantly cheaper to ensure data consistency prior to loading the data then ensuring data consistency while loading it into the database. The <code class="literal">storage.batch-loading</code> configuration option exists because of this observation.</p><p>For example, consider the use case of bulk loading existing user profiles into JanusGraph. Furthermore, assume that the username property key has a unique composite index defined on it, i.e. usernames must be unique across the entire graph. If the user profiles are imported from another database, username uniqueness might already guaranteed. If not, it is simple to sort the profiles by name and filter out duplicates or writing a Hadoop job that does such filtering. Now, we can enable <code class="literal">storage.batch-loading</code> which significantly reduces the bulk loading time because JanusGraph does not have to check for every added user whether the name already exists in the database.</p><p><span class="strong"><strong>Important</strong></span>: Enabling <code class="literal">storage.batch-loading</code> requires the user to ensure that the loaded data is internally consistent and consistent with any data already in the graph. In particular, concurrent type creation can lead to severe data integrity issues when batch loading is enabled. Hence, we <span class="strong"><strong>strongly</strong></span> encourage disabling automatic type creation by setting <code class="literal">schema.default = none</code> in the graph configuration.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_optimizing_id_allocation"></a>33.1.2.&nbsp;Optimizing ID Allocation</h3></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_id_block_size"></a>33.1.2.1.&nbsp;ID Block Size</h4></div></div></div><p>Each newly added vertex or edge is assigned a unique id. JanusGraph&#8217;s id pool manager acquires ids in blocks for a particular JanusGraph instance. The id block acquisition process is expensive because it needs to guarantee globally unique assignment of blocks. Increasing <code class="literal">ids.block-size</code> reduces the number of acquisitions but potentially leaves many ids unassigned and hence wasted. For transactional workloads the default block size is reasonable, but during bulk loading vertices and edges are added much more frequently and in rapid succession. Hence, it is generally advisable to increase the block size by a factor of 10 or more depending on the number of vertices to be added per machine.</p><p><span class="strong"><strong>Rule of thumb</strong></span>: Set <code class="literal">ids.block-size</code> to the number of vertices you expect to add per JanusGraph instance per hour.</p><p><span class="strong"><strong>Important:</strong></span> All JanusGraph instances MUST be configured with the same value for <code class="literal">ids.block-size</code> to ensure proper id allocation. Hence, be careful to shut down all JanusGraph instances prior to changing this value.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_id_acquisition_process"></a>33.1.2.2.&nbsp;ID Acquisition Process</h4></div></div></div><p>When id blocks are frequently allocated by many JanusGraph instances in parallel, allocation conflicts between instances will inevitably arise and slow down the allocation process. In addition, the increased write load due to bulk loading may further slow down the process to the point where JanusGraph considers it failed and throws an exception. There are three configuration options that can be tuned to avoid this.</p><p>1) <code class="literal">ids.authority.wait-time</code> configures the time in milliseconds the id pool manager waits for an id block application to be acknowledged by the storage backend. The shorter this time, the more likely it is that an application will fail on a congested storage cluster.</p><p><span class="strong"><strong>Rule of thumb</strong></span>: Set this to the sum of the 95th percentile read and write times measured on the storage backend cluster under load.
<span class="strong"><strong>Important</strong></span>: This value should be the same across all JanusGraph instances.</p><p>2) <code class="literal">ids.renew-timeout</code> configures the number of milliseconds JanusGraph&#8217;s id pool manager will wait in total while attempting to acquire a new id block before failing.</p><p><span class="strong"><strong>Rule of thumb</strong></span>: Set this value to be as large feasible to not have to wait too long for unrecoverable failures. The only downside of increasing it is that JanusGraph will try for a long time on an unavailable storage backend cluster.</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_optimizing_writes_and_reads"></a>33.1.3.&nbsp;Optimizing Writes and Reads</h3></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_buffer_size"></a>33.1.3.1.&nbsp;Buffer Size</h4></div></div></div><p>JanusGraph buffers writes and executes them in small batches to reduce the number of requests against the storage backend. The size of these batches is controlled by <code class="literal">storage.buffer-size</code>. When executing a lot of writes in a short period of time, it is possible that the storage backend can become overloaded with write requests. In that case, increasing <code class="literal">storage.buffer-size</code> can avoid failure by increasing the number of writes per request and thereby lowering the number of requests.</p><p>However, increasing the buffer size increases the latency of the write request and its likelihood of failure. Hence, it is not advisable to increase this setting for transactional loads and one should carefully experiment with this setting during bulk loading.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_read_and_write_robustness"></a>33.1.3.2.&nbsp;Read and Write Robustness</h4></div></div></div><p>During bulk loading, the load on the cluster typically increases making it more likely for read and write operations to fail (in particular if the buffer size is increased as described above).
<code class="literal">storage.read-attempts</code> and <code class="literal">storage.write-attempts</code> configure how many times JanusGraph will attempt to execute a read or write operation against the storage backend before giving up. If it is expected that there is a high load on the backend during bulk loading, it is generally advisable to increase these configuration options.</p><p><code class="literal">storage.attempt-wait</code> specifies the number of milliseconds that JanusGraph will wait before re-attempting a failed backend operation. A higher value can ensure that operation re-tries do not further increase the load on the backend.</p></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_strategies"></a>33.2.&nbsp;Strategies</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_parallelizing_the_load"></a>33.2.1.&nbsp;Parallelizing the Load</h3></div></div></div><p>By parallelizing the bulk loading across multiple machines, the load time can be greatly reduced if JanusGraph&#8217;s storage backend cluster is large enough to serve the additional requests. This is essentially the approach <a class="xref" href="hadoop-tp3.html" title="Chapter&nbsp;36.&nbsp;JanusGraph with TinkerPop&#8217;s Hadoop-Gremlin">Chapter&nbsp;36, <i>JanusGraph with TinkerPop&#8217;s Hadoop-Gremlin</i></a> takes to bulk loading data into JanusGraph using MapReduce.</p><p>If Hadoop cannot be used for parallelizing the bulk loading process, here are some high level guidelines for effectively parallelizing the loading process:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">In some cases, the graph data can be decomposed into multiple disconnected subgraphs. Those subgraphs can be loaded independently in parallel across multiple machines (for instance, using BatchGraph as described above).</li><li class="listitem"><p class="simpara">If the graph cannot be decomposed, it is often beneficial to load in multiple steps where the last two steps can be parallelized across multiple machines:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">Make sure the vertex and edge data sets are de-duplicated and consistent.</li><li class="listitem">Set <code class="literal">batch-loading=true</code>. Possibly optimize additional configuration settings described above.</li><li class="listitem">Add all the vertices with their properties to the graph (but no edges). Maintain a (distributed) map from vertex id (as defined by the loaded data) to JanusGraph&#8217;s internal vertex id (i.e. <code class="literal">vertex.getId()</code>) which is a 64 bit long id.</li><li class="listitem">Add all the edges using the map to look-up JanusGraph&#8217;s vertex id and retrieving the vertices using that id.</li></ol></div></li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_q_a"></a>33.3.&nbsp;Q&amp;A</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><span class="strong"><strong>What should I do to avoid the following exception during batch-loading:</strong></span> <code class="literal">java.io.IOException: ID renewal thread on partition [X] did not complete in time.</code>?
This exception is mostly likely caused by repeated time-outs during the id allocation phase due to highly stressed storage backend. Refer to the section on <span class="emphasis"><em>ID Allocation Optimization</em></span> above.</li></ul></div></div></div></div><div class="clearer"></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="index-admin.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="advanced.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="graph-partitioning.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Chapter&nbsp;32.&nbsp;Index Management&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;Chapter&nbsp;34.&nbsp;Graph Partitioning</td></tr></table></div><div class="footer-wrapper"><footer id="footer"><div class="copyright">
              Copyright &copy; 2017 JanusGraph Authors. All rights reserved.<br>
              The Linux Foundation has registered trademarks and uses trademarks. For a list of<br>
              trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a> page.<br>
              Cassandra, Groovy, HBase, Hadoop, Lucene, Solr, and TinkerPop are trademarks of the Apache Software Foundation.<br>
              Berkeley DB and Berkeley DB Java Edition are trademarks of Oracle.<br>
              Documentation generated with <a href="http://www.methods.co.nz/asciidoc/">AsciiDoc</a>, <a href="http://asciidoctor.org/">AsciiDoctor</a>, <a href="http://docbook.sourceforge.net/">DocBook</a>, and <a href="http://saxon.sourceforge.net/">Saxon</a>.
        	  </div></footer></div></div></body></html>