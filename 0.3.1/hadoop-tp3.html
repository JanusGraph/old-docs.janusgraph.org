<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>Chapter&nbsp;37.&nbsp;JanusGraph with TinkerPop&#8217;s Hadoop-Gremlin</title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="JanusGraph Documentation"><link rel="up" href="advanced.html" title="Part&nbsp;V.&nbsp;Advanced Topics"><link rel="prev" href="serializer.html" title="Chapter&nbsp;36.&nbsp;Datatype and Attribute Serializer Configuration"><link rel="next" href="monitoring.html" title="Chapter&nbsp;38.&nbsp;Monitoring JanusGraph"><script xmlns:d="http://docbook.org/ns/docbook" type="text/javascript" src="js/jquery/jquery-1.11.0.js"></script><script xmlns:d="http://docbook.org/ns/docbook" type="text/javascript" src="js/jquery/jquery-migrate-1.2.1.min.js"></script><link xmlns:d="http://docbook.org/ns/docbook" rel="stylesheet" id="inline-blob-janusgraph-docs-specific" href="css/docs.css" type="text/css" media="all"><link xmlns:d="http://docbook.org/ns/docbook" rel="apple-touch-icon" type="image/png" href="images/janusgraph-logomark.png"><script xmlns:d="http://docbook.org/ns/docbook" type="text/javascript">
      WebFontConfig = {
        google: {
          families: [
            "Lato:400,400italic,700,700italic:latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese",
            "Open+Sans:400,400italic,700,700italic:latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese",
            "Antic+Slab:400,400italic,700,700italic:latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese"
          ]
        }
      };
      (function() {
      var wf = document.createElement('script');
      wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
        '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
	wf.type = 'text/javascript';
	wf.async = 'true';
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(wf, s);
	})();
    </script></head><body xmlns:d="http://docbook.org/ns/docbook" bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div id="wrapper"><div class="header-wrapper"><header id="header"><ul class="header-list"><li class="header-item"><a href="http://janusgraph.org"><img src="images/janusgraph-logo.png" alt="JanusGraph" class="normal_logo"></a></li><li class="header-item-right"><a href="https://github.com/JanusGraph/janusgraph/releases">Download JanusGraph</a></li><li class="header-item-right dropdown"><a href="https://docs.janusgraph.org/latest/doc-versions.html">Other Doc Versions</a><div class="dropdown-content"><a href="https://docs.janusgraph.org/latest/index.html">Latest</a><a href="https://docs.janusgraph.org/0.3.1/index.html">Version 0.3.1</a><a href="https://docs.janusgraph.org/0.3.0/index.html">Version 0.3.0</a><a href="https://docs.janusgraph.org/0.2.2/index.html">Version 0.2.2</a><a href="https://docs.janusgraph.org/0.2.1/index.html">Version 0.2.1</a><a href="https://docs.janusgraph.org/0.2.0/index.html">Version 0.2.0</a><a href="https://docs.janusgraph.org/0.1.1/index.html">Version 0.1.1</a><a href="https://docs.janusgraph.org/0.1.0/index.html">Version 0.1.0</a></div></li><li class="header-item-right"><a href="index.html">Documentation (0.3.1)</a></li></ul></header></div><div id="main" class="clearfix width-100"><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">JanusGraph Documentation</a></span> &gt; <span class="breadcrumb-link"><a href="advanced.html">Advanced Topics</a></span> &gt; <span class="breadcrumb-node">JanusGraph with TinkerPop&#8217;s Hadoop-Gremlin</span></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="hadoop-tp3"></a>Chapter&nbsp;37.&nbsp;JanusGraph with TinkerPop&#8217;s Hadoop-Gremlin</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl class="toc"><dt><span class="section"><a href="hadoop-tp3.html#_configuring_hadoop_for_running_olap">37.1. Configuring Hadoop for Running OLAP</a></span></dt><dt><span class="section"><a href="hadoop-tp3.html#_olap_traversals">37.2. OLAP Traversals</a></span></dt><dd><dl><dt><span class="section"><a href="hadoop-tp3.html#_olap_traversals_with_spark_local">37.2.1. OLAP Traversals with Spark Local</a></span></dt><dt><span class="section"><a href="hadoop-tp3.html#_olap_traversals_with_spark_standalone_cluster">37.2.2. OLAP Traversals with Spark Standalone Cluster</a></span></dt></dl></dd><dt><span class="section"><a href="hadoop-tp3.html#_other_vertex_programs">37.3. Other Vertex Programs</a></span></dt></dl></div><p>This chapter describes how to leverage <a class="link" href="https://hadoop.apache.org/" target="_top">Apache Hadoop</a> and <a class="link" href="https://spark.apache.org/" target="_top">Apache Spark</a> to configure JanusGraph for distributed graph processing. These steps will provide an overview on how to get started with those projects, but please refer to those project communities to become more deeply familiar with them.</p><p>JanusGraph-Hadoop works with TinkerPop&#8217;s <a class="link" href="https://tinkerpop.apache.org/docs/3.3.3/reference/#hadoop-gremlin" target="_top">hadoop-gremlin</a> package for
general-purpose OLAP.</p><p>For the scope of the example below, Apache Spark is the computing framework and Apache Cassandra is the storage backend. The directions can be followed with other packages with minor changes to the configuration properties.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The examples in this chapter are based on running Spark in local mode or standalone cluster mode. Additional configuration
is required when using Spark on YARN or Mesos.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configuring_hadoop_for_running_olap"></a>37.1.&nbsp;Configuring Hadoop for Running OLAP</h2></div></div></div><p>For running OLAP queries from the Gremlin Console, a few prerequisites need to be fulfilled. You will need to add the Hadoop configuration directory into the <code class="literal">CLASSPATH</code>, and the configuration directory needs to point to a live Hadoop cluster.</p><p>Hadoop provides a distributed access-controlled file system. The Hadoop file system is used by Spark workers running on different machines to have a common source for file based operations. The intermediate computations of various OLAP queries may be persisted on the Hadoop file system.</p><p>For configuring a single node Hadoop cluster, please refer to official <a class="link" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_top">Apache Hadoop Docs</a></p><p>Once you have a Hadoop cluster up and running, we will need to specify the Hadoop configuration files in the <code class="literal">CLASSPATH</code>. The below document expects that you have those configuration files located under <code class="literal">/etc/hadoop/conf</code>.</p><p>Once verified, follow the below steps to add the Hadoop configuration to the <code class="literal">CLASSPATH</code> and start the Gremlin Console, which will play the role of the Spark driver program.</p><pre class="programlisting">export HADOOP_CONF_DIR=/etc/hadoop/conf
export CLASSPATH=$HADOOP_CONF_DIR
bin/gremlin.sh</pre><p>Once the path to Hadoop configuration has been added to the <code class="literal">CLASSPATH</code>, we can verify whether the Gremlin Console can access the Hadoop cluster by following these quick steps:</p><pre class="programlisting"><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>hdfs<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>storage[org.apache.hadoop.fs.LocalFileSystem@<span class="hl-number">65</span>bb9029]<span class="hl-gremlin-func"> </span><em class="hl-comment">// BAD</em><span class="hl-gremlin-func">
</span><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>hdfs<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>storage[DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_<span class="hl-number">1229457199</span>_<span class="hl-number">1</span>,<span class="hl-gremlin-func"> </span>ugi=user<span class="hl-gremlin-func"> </span><span class="hl-gremlin-func">(</span>auth:SIMPLE<span class="hl-gremlin-func">)</span>]]]<span class="hl-gremlin-func"> </span><em class="hl-comment">// GOOD</em></pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_olap_traversals"></a>37.2.&nbsp;OLAP Traversals</h2></div></div></div><p>JanusGraph-Hadoop works with TinkerPop&#8217;s hadoop-gremlin package for general-purpose OLAP to traverse over the graph, and parallelize queries by leveraging Apache Spark.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_olap_traversals_with_spark_local"></a>37.2.1.&nbsp;OLAP Traversals with Spark Local</h3></div></div></div><p>The backend demonstrated here is Cassandra for the OLAP example below. Additional configuration will be needed that is specific to that storage backend. The configuration is specified by the <code class="literal">gremlin.hadoop.graphReader</code> property which specifies the class to read data from the storage backend.</p><p>JanusGraph currently supports following graphReader classes:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><code class="literal">Cassandra3InputFormat</code> for use with Cassandra 3</li><li class="listitem"><code class="literal">CassandraInputFormat</code> for use with Cassandra 2</li><li class="listitem"><code class="literal">HBaseInputFormat</code> and <code class="literal">HBaseSnapshotInputFormat</code> for use with HBase</li></ul></div><p>The following properties file can be used to connect a JanusGraph instance in Cassandra such that it can be used with HadoopGraph to run OLAP queries.</p><pre class="programlisting"><em class="hl-comment"># read-cassandra-3.properties</em>
<em class="hl-comment">#</em>
<em class="hl-comment"># Hadoop Graph Configuration</em>
<em class="hl-comment">#</em>
<span class="hl-attribute">gremlin.graph</span>=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph
<span class="hl-attribute">gremlin.hadoop.graphReader</span>=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormat
<span class="hl-attribute">gremlin.hadoop.graphWriter</span>=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat

<span class="hl-attribute">gremlin.hadoop.jarsInDistributedCache</span>=true
<span class="hl-attribute">gremlin.hadoop.inputLocation</span>=none
<span class="hl-attribute">gremlin.hadoop.outputLocation</span>=output
<span class="hl-attribute">gremlin.spark.persistContext</span>=true

<em class="hl-comment">#</em>
<em class="hl-comment"># JanusGraph Cassandra InputFormat configuration</em>
<em class="hl-comment">#</em>
<em class="hl-comment"># These properties defines the connection properties which were used while write data to JanusGraph.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.backend</span>=cassandra
<em class="hl-comment"># This specifies the hostname &amp; port for Cassandra data store.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.hostname</span>=127.0.0.1
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.port</span>=9160
<em class="hl-comment"># This specifies the keyspace where data is stored.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.cassandra.keyspace</span>=janusgraph
<em class="hl-comment"># This defines the indexing backned configuration used while writing data to JanusGraph.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.index.search.backend</span>=elasticsearch
<span class="hl-attribute">janusgraphmr.ioformat.conf.index.search.hostname</span>=127.0.0.1
<em class="hl-comment"># Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr).</em>

<em class="hl-comment">#</em>
<em class="hl-comment"># Apache Cassandra InputFormat configuration</em>
<em class="hl-comment">#</em>
<span class="hl-attribute">cassandra.input.partitioner.class</span>=org.apache.cassandra.dht.Murmur3Partitioner

<em class="hl-comment">#</em>
<em class="hl-comment"># SparkGraphComputer Configuration</em>
<em class="hl-comment">#</em>
<span class="hl-attribute">spark.master</span>=local[*]
<span class="hl-attribute">spark.executor.memory</span>=1g
<span class="hl-attribute">spark.serializer</span>=org.apache.spark.serializer.KryoSerializer
<span class="hl-attribute">spark.kryo.registrator</span>=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator
</pre><p>First create a properties file with above configurations, and load the same on the Gremlin Console to run OLAP queries as follows:</p><pre class="programlisting">bin/gremlin.sh<span class="hl-gremlin-func">
</span><span class="hl-gremlin-func">
</span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span>\,,,/<span class="hl-gremlin-func">
</span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func">(</span>o<span class="hl-gremlin-func"> </span>o<span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span>-----oOOo-<span class="hl-gremlin-func">(</span><span class="hl-number">3</span><span class="hl-gremlin-func">)</span>-oOOo-----<span class="hl-gremlin-func">
</span>plug<span class="hl-gremlin-func">in </span>activated:<span class="hl-gremlin-func"> </span>janusgraph.imports<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>:plug<span class="hl-gremlin-func">in </span>use<span class="hl-gremlin-func"> </span>tinkerpop.hadoop<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>tinkerpop.hadoop<span class="hl-gremlin-func"> </span>activated<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>:plug<span class="hl-gremlin-func">in </span>use<span class="hl-gremlin-func"> </span>tinkerpop.spark<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>tinkerpop.spark<span class="hl-gremlin-func"> </span>activated<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span><em class="hl-comment">// 1. Open a the graph for OLAP processing reading in from Cassandra 3</em><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>graph<span class="hl-gremlin-func"> </span>=<span class="hl-gremlin-func"> </span>GraphFactory.open<span class="hl-gremlin-func">(</span><span class="hl-string">'conf/hadoop-graph/read-cassandra-3.properties'</span><span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>hadoopgraph[cassandra3inputformat-&gt;gryooutputformat]<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span><em class="hl-comment">// 2. Configure the traversal to run with Spark</em><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>g<span class="hl-gremlin-func"> </span>=<span class="hl-gremlin-func"> </span>graph.traversal<span class="hl-gremlin-func">(</span><span class="hl-gremlin-func">)</span>.withComputer<span class="hl-gremlin-func">(</span>SparkGraphComputer<span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>graphtraversalsource[hadoopgraph[cassandra3inputformat-&gt;gryooutputformat],<span class="hl-gremlin-func"> </span>sparkgraphcomputer]<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span><em class="hl-comment">// 3. Run some OLAP traversals</em><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>g.<span class="hl-gremlin-func">V(</span><span class="hl-gremlin-func">)</span>.count<span class="hl-gremlin-func">(</span><span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span>......<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span><span class="hl-number">808</span><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>g.<span class="hl-gremlin-func">E(</span><span class="hl-gremlin-func">)</span>.count<span class="hl-gremlin-func">(</span><span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span>......<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span><span class="hl-gremlin-func"> </span><span class="hl-number">8046</span></pre></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_olap_traversals_with_spark_standalone_cluster"></a>37.2.2.&nbsp;OLAP Traversals with Spark Standalone Cluster</h3></div></div></div><p>The steps followed in the previous section can also be used with a Spark standalone cluster with only minor changes:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Update the <code class="literal">spark.master</code> property to point to the Spark master URL instead of local</li><li class="listitem">Update the <code class="literal">spark.executor.extraClassPath</code> to enable the Spark executor to find the JanusGraph dependency jars</li><li class="listitem">Copy the JanusGraph dependency jars into the location specified in the previous step on each Spark executor machine</li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>We have copied all the jars under <span class="strong"><strong>janusgraph-distribution/lib</strong></span> into /opt/lib/janusgraph/ and the same directory structure is created across all workers, and jars are manually copied across all workers.</p></td></tr></table></div><p>The final properties file used for OLAP traversal is as follows:</p><pre class="programlisting"><em class="hl-comment"># read-cassandra-3.properties</em>
<em class="hl-comment">#</em>
<em class="hl-comment"># Hadoop Graph Configuration</em>
<em class="hl-comment">#</em>
<span class="hl-attribute">gremlin.graph</span>=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph
<span class="hl-attribute">gremlin.hadoop.graphReader</span>=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormat
<span class="hl-attribute">gremlin.hadoop.graphWriter</span>=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat

<span class="hl-attribute">gremlin.hadoop.jarsInDistributedCache</span>=true
<span class="hl-attribute">gremlin.hadoop.inputLocation</span>=none
<span class="hl-attribute">gremlin.hadoop.outputLocation</span>=output
<span class="hl-attribute">gremlin.spark.persistContext</span>=true

<em class="hl-comment">#</em>
<em class="hl-comment"># JanusGraph Cassandra InputFormat configuration</em>
<em class="hl-comment">#</em>
<em class="hl-comment"># These properties defines the connection properties which were used while write data to JanusGraph.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.backend</span>=cassandra
<em class="hl-comment"># This specifies the hostname &amp; port for Cassandra data store.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.hostname</span>=127.0.0.1
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.port</span>=9160
<em class="hl-comment"># This specifies the keyspace where data is stored.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.storage.cassandra.keyspace</span>=janusgraph
<em class="hl-comment"># This defines the indexing backned configuration used while writing data to JanusGraph.</em>
<span class="hl-attribute">janusgraphmr.ioformat.conf.index.search.backend</span>=elasticsearch
<span class="hl-attribute">janusgraphmr.ioformat.conf.index.search.hostname</span>=127.0.0.1
<em class="hl-comment"># Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr).</em>

<em class="hl-comment">#</em>
<em class="hl-comment"># Apache Cassandra InputFormat configuration</em>
<em class="hl-comment">#</em>
<span class="hl-attribute">cassandra.input.partitioner.class</span>=org.apache.cassandra.dht.Murmur3Partitioner

<em class="hl-comment">#</em>
<em class="hl-comment"># SparkGraphComputer Configuration</em>
<em class="hl-comment">#</em>
<span class="hl-attribute">spark.master=spark://127.0.0.1</span>:7077
<span class="hl-attribute">spark.executor.memory</span>=1g
<span class="hl-attribute">spark.executor.extraClassPath</span>=/opt/lib/janusgraph/*
<span class="hl-attribute">spark.serializer</span>=org.apache.spark.serializer.KryoSerializer
<span class="hl-attribute">spark.kryo.registrator</span>=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator</pre><p>Then use the properties file as follows from the Gremlin Console:</p><pre class="programlisting">bin/gremlin.sh<span class="hl-gremlin-func">
</span><span class="hl-gremlin-func">
</span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span>\,,,/<span class="hl-gremlin-func">
</span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func"> </span><span class="hl-gremlin-func">(</span>o<span class="hl-gremlin-func"> </span>o<span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span>-----oOOo-<span class="hl-gremlin-func">(</span><span class="hl-number">3</span><span class="hl-gremlin-func">)</span>-oOOo-----<span class="hl-gremlin-func">
</span>plug<span class="hl-gremlin-func">in </span>activated:<span class="hl-gremlin-func"> </span>janusgraph.imports<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>:plug<span class="hl-gremlin-func">in </span>use<span class="hl-gremlin-func"> </span>tinkerpop.hadoop<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>tinkerpop.hadoop<span class="hl-gremlin-func"> </span>activated<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>:plug<span class="hl-gremlin-func">in </span>use<span class="hl-gremlin-func"> </span>tinkerpop.spark<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>tinkerpop.spark<span class="hl-gremlin-func"> </span>activated<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span><em class="hl-comment">// 1. Open a the graph for OLAP processing reading in from Cassandra 3</em><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>graph<span class="hl-gremlin-func"> </span>=<span class="hl-gremlin-func"> </span>GraphFactory.open<span class="hl-gremlin-func">(</span><span class="hl-string">'conf/hadoop-graph/read-cassandra-3.properties'</span><span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>hadoopgraph[cassandra3inputformat-&gt;gryooutputformat]<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span><em class="hl-comment">// 2. Configure the traversal to run with Spark</em><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>g<span class="hl-gremlin-func"> </span>=<span class="hl-gremlin-func"> </span>graph.traversal<span class="hl-gremlin-func">(</span><span class="hl-gremlin-func">)</span>.withComputer<span class="hl-gremlin-func">(</span>SparkGraphComputer<span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span>graphtraversalsource[hadoopgraph[cassandra3inputformat-&gt;gryooutputformat],<span class="hl-gremlin-func"> </span>sparkgraphcomputer]<span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span><em class="hl-comment">// 3. Run some OLAP traversals</em><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>g.<span class="hl-gremlin-func">V(</span><span class="hl-gremlin-func">)</span>.count<span class="hl-gremlin-func">(</span><span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span>......<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span><span class="hl-number">808</span><span class="hl-gremlin-func">
</span><span class="hl-repl-prompt">gremlin&gt;</span><span class="hl-gremlin-func"> </span>g.<span class="hl-gremlin-func">E(</span><span class="hl-gremlin-func">)</span>.count<span class="hl-gremlin-func">(</span><span class="hl-gremlin-func">)</span><span class="hl-gremlin-func">
</span>......<span class="hl-gremlin-func">
</span><span class="hl-repl-result">==&gt;</span><span class="hl-gremlin-func"> </span><span class="hl-number">8046</span></pre></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_other_vertex_programs"></a>37.3.&nbsp;Other Vertex Programs</h2></div></div></div><p>Apache TinkerPop provides various vertex programs. A vertex program runs on each vertex until either a termination criteria is attained or a fixed number of iterations has been reached. Due to the parallel nature of vertex programs, they can leverage parallel computing frameworks like Spark or Giraph to improve their performance.</p><p>Once you are familiar with how to configure JanusGraph to work with Spark, you can run all the other vertex programs provided by Apache TinkerPop, like Page Rank, Bulk Loading and Peer Pressure. See the <a class="link" href="http://tinkerpop.apache.org/docs/3.3.3/reference/#vertexprogram" target="_top">TinkerPop VertexProgram docs</a> for more details.</p></div></div></div><div class="clearer"></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="serializer.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="advanced.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="monitoring.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Chapter&nbsp;36.&nbsp;Datatype and Attribute Serializer Configuration&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;Chapter&nbsp;38.&nbsp;Monitoring JanusGraph</td></tr></table></div><div class="footer-wrapper"><footer id="footer"><div class="copyright">
              Copyright &copy; 2017 JanusGraph Authors. All rights reserved.<br>
              The Linux Foundation has registered trademarks and uses trademarks. For a list of<br>
              trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a> page.<br>
              Cassandra, Groovy, HBase, Hadoop, Lucene, Solr, and TinkerPop are trademarks of the Apache Software Foundation.<br>
              Berkeley DB and Berkeley DB Java Edition are trademarks of Oracle.<br>
              Documentation generated with <a href="http://www.methods.co.nz/asciidoc/">AsciiDoc</a>, <a href="http://asciidoctor.org/">AsciiDoctor</a>, <a href="http://docbook.sourceforge.net/">DocBook</a>, and <a href="http://saxon.sourceforge.net/">Saxon</a>.
        	  </div></footer></div></div></body></html>